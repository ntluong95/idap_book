---
title: 'Group-Level Data Transformations in Pandas'
---

```{python}
# | echo: false
# Setup
import pandas as pd

pd.options.display.max_rows = 10
```

## Introduction

In our previous lessons, you've learned how to perform basic data manipulation and aggregation using pandas. Now, we'll take a step further by exploring some additional useful **group data transformations**. These operations allow you to compute statistics and perform calculations within specific groups in your dataset.

## Learning Objectives

By the end of this lesson, you will be able to:

- Add group-level summary statistics as new columns using `transform()`.
- Count values within groups using `value_counts()`.
- Compute cumulative sums within groups.
- Sort data within groups to extract minimum, maximum, and top N values with `apply()` and lambda functions.

## Imports

This lesson will require `pandas`, `numpy`, `plotly.express`, and `vega_datasets`:

```{python}
import pandas as pd
import vega_datasets as vd
import plotly.express as px
import warnings
import calendar

warnings.filterwarnings("ignore") ## There is a class of warnings that come up when working with categorical data with the current version of pandas that we can ignore
```

## Data

We'll use the `seattle_2012` dataset for our examples.

```{python}
seattle_weather = vd.data.seattle_weather()

# Select just 2012 data using query and add a month column
seattle_2012 = seattle_weather.query("date.dt.year == 2012")
seattle_2012["month"] = pd.Categorical(
    seattle_2012["date"].dt.strftime("%B"),
    categories=list(calendar.month_name[1:]),
    ordered=True,
)
seattle_2012
```


We can increase the number of rows that pandas displays using `pd.options.display.max_rows`. Let's set it to 20 for this lesson:

```{python}
# | eval: false
pd.options.display.max_rows = 20
```

## Adding Group-Level Summary Statistics Using `transform()`

In the previous lesson, you learned how to calculate summary statistics like mean, median, or standard deviation using `agg()`. 

For example, to compute the mean precipitation (rain + snow) for each month, you could use:

```{python}
seattle_2012.groupby('month').agg(mean_precip = ('precipitation', 'mean'))
```

Sometimes, we want to add these group-level statistics as new columns to our original DataFrame. We can't do this directly with the `agg()` output: 

```{python}
# Does not work
seattle_2012['mean_precip'] = seattle_2012.groupby('month').agg(mean_precip = ('precipitation', 'mean'))
seattle_2012
```

But we can do this using `transform()`. `transform()` reshapes the output to match the original DataFrame's shape, allowing us to add the group-level statistics as new columns.

```{python}
seattle_2012['mean_precip_month'] = seattle_2012.groupby('month')['precipitation'].transform('mean')
seattle_2012
```

Now we can, for example, calculate the difference between the actual precipitation and the average precipitation for that month:

```{python}
seattle_2012['precip_diff_from_mean'] = seattle_2012['precipitation'] - seattle_2012['mean_precip_month']
seattle_2012
```

You can compute other statistics similarly. For example, to compute the median precipitation for each month, you could use:

```{python}
seattle_2012['prep_median_month'] = seattle_2012.groupby('month')['precipitation'].transform('median')    
seattle_2012
```

::: {.callout-tip title="Practice"}

## Practice Q: Mean tip amount by sex

Using the `tips` dataset, add a new column `mean_tip_day` that contains the mean tip amount for each day (`Sun`, `Sat`, etc.), then calculate the difference between each person's tip and the mean tip for that day.

```{python}
# Your code here:
tips = px.data.tips()
tips
```

The first few rows of your output data should look something like this:

```
total_bill   tip    sex     smoker   day   time     size   mean_tip_sex   tip_diff_from_mean
16.99        1.01   Female  No       Sun   Dinner   2      2.833448       -1.823448
10.34        1.66   Male    No       Sun   Dinner   3      3.089618       -1.429618  
21.01        3.50   Male    No       Sun   Dinner   3      3.089618        0.410382
```

```{python}
# | echo: false
# | eval: false
tips['mean_tip_sex'] = tips.groupby('sex')['tip'].transform('mean')
tips['tip_diff_from_mean'] = tips['tip'] - tips['mean_tip_sex']
tips
```

:::

Let's reinitialize the `seattle_2012` DataFrame to a smaller set of columns for the rest of the lesson:

```{python}
seattle_2012 = seattle_2012[['date', 'month', 'precipitation', 'wind', 'weather']]
seattle_2012
```


## Counting Values Within Groups Using `value_counts()`

Counting occurrences of categorical variables within groups can reveal interesting patterns, and you often need to do this after using `groupby()`.

First, let's recall how `value_counts()` works on the entire DataFrame.

```{python}
# Count of weather types
seattle_2012["weather"].value_counts()
```

We can add `normalize=True` to get proportions:

```{python}
seattle_2012['weather'].value_counts(normalize=True)
```

Now, to count weather types within each month, we first group by `month`, then subset the `weather` column and apply `value_counts()` to it.

```{python}
# Counts of weather types per month
seattle_2012.groupby('month')['weather'].value_counts()
```

This returns a Series with a MultiIndex, which can be converted to a regular DataFrame with `reset_index()`:

```{python}
seattle_2012.groupby('month')['weather'].value_counts().reset_index()
```

::: {.callout-tip title="Practice"}

## Practice Q: Count Smokers and Non-Smokers by Day

Using the `tips` dataset, count the number of smokers and non-smokers for each day.

```{python}
tips = px.data.tips()
tips

# Your code here:
```

The first few rows of your result should look something like this:

```
day	smoker	count
Fri	Yes	15
Fri	No	4
Sat	No	45
```

```{python}
# | echo: false
# | eval: false
## Solution
smoker_counts = tips.groupby("day")["smoker"].value_counts().reset_index(name="count")
smoker_counts
```

:::

## Counting Values that Meet a Condition

To count the number of values that meet a condition within groups, one approach is to create a new boolean column and then apply `value_counts()` to it. For example, to count the number of days with more than 10 inches of precipitation:

```{python}
seattle_2012['high_precip'] = seattle_2012['precipitation'] > 10
seattle_2012['high_precip'].value_counts()
```

We can now group by `month` and count the number of `True` values per month:

```{python}
seattle_2012.groupby('month')['high_precip'].value_counts().reset_index()
```

::: {.callout-tip title="Practice"}

## Practice Q: Count Time of Day per Sex

In the `tips` dataset, count how many times each sex (`Male`, `Female`) appears in each time category (`Lunch`, `Dinner`).

The first three rows of your output data should look something like this:

```
sex	time	count
Female	Dinner	52
Female	Lunch	35
Male	Dinner	124
```

```{python}
# | echo: false
# | eval: false
sex_time_counts = tips.groupby('sex')['time'].value_counts().reset_index(name='count')
sex_time_counts
```

:::

## Computing Cumulative Sums Within Groups

Cumulative sums help track running totals within groups. This is an often-useful operation. Let's see how we can do this to grouped data.

As a recall, here's how we can compute the cumulative sum of precipitation for the entire DataFrame:

```{python}
# Cumulative sum of precipitation
seattle_2012["precip_cumul"] = seattle_2012["precipitation"].cumsum()
seattle_2012
```

To compute cumulative precipitation within each month, we can use `groupby()` and `cumsum()`:

```{python}
# Cumulative precipitation per month
seattle_2012["precip_cumul"] = seattle_2012.groupby("month")["precipitation"].cumsum()
seattle_2012
```

::: {.callout-practice title="Practice Q1: Cumulative Tip Amount by Day"}

## Practice Q: Cumulative Tip Amount by Day

Using the `tips` dataset, compute the cumulative sum of `total_bill` for each `day`, adding a new column `cumul_total_bill_day`. Then add another column `cumul_tip_day` that contains the cumulative sum of `tip` for each `day`.

```{python}
# Your code 
```

```{python}
# | echo: false
# | eval: false
tips["cumul_tip_day"] = tips.groupby("day")["tip"].cumsum()
tips["cumul_total_bill_day"] = tips.groupby("day")["total_bill"].cumsum()
tips
```

:::

## Sorting Data Within Groups

Let's reinitialize the `seattle_2012` DataFrame to a smaller set of columns:

```{python}
seattle_2012 = seattle_2012[['date', 'month', 'precipitation', 'wind', 'weather']]
seattle_2012
```

Sorting within groups allows us to find minimums, maximums, or top N values in each group. Let's see how we can do this to grouped data.

As a refresher, here's how we can sort the entire DataFrame by precipitation:

```{python}
# Sort by precipitation descending
seattle_2012_sorted = seattle_2012.sort_values('precipitation')
seattle_2012_sorted
```

Or, in descending order:

```{python}
seattle_2012_sorted = seattle_2012.sort_values('precipitation', ascending=False)
seattle_2012_sorted
```

Now, unfortunately, the `sort_values()` method cannot be called directly on a grouped object:

```{python}
# | eval: false
# Does not work
seattle_2012.groupby("month").sort_values("precipitation")
```

```
AttributeError: 'DataFrameGroupBy' object has no attribute 'sort_values'
```
To sort precipitation within each month, we need to use `groupby()` and `apply()`. The apply method accepts some function which will be applied to each group. 

Let's define a custom sort function that sorts the values within each group:

```{python}
def sort_precipitation(df):
    return df.sort_values('precipitation', ascending=False)
```

Now we can apply this function to each group:

```{python}
# Sort precipitation within each month
seattle_2012.groupby("month", group_keys=False).apply(sort_precipitation)
```

Since the function is very simple, it would be better to use a lambda function:

```{python}
seattle_2012.groupby("month", group_keys=False).apply(lambda x: x.sort_values("precipitation", ascending=False))
```

We can extend this approach to get the top N values within each group by adding `.head(N)`. For example, let's obtain the day with the most precipitation in each month:

```{python}
# Top 3 days with the highest precipitation in each month
seattle_2012.groupby("month", group_keys=False).apply(lambda x: x.sort_values("precipitation", ascending=False).head(1))
```

Or to get the top 3 days with the highest precipitation in each month:

```{python}
# Top 3 days with the highest precipitation in each month
seattle_2012.groupby("month", group_keys=False).apply(lambda x: x.sort_values("precipitation", ascending=False).head(3))
```

### Practice Questions

::: {.callout-practice title="Practice Q1: Top 2 Highest Tips per Day"}

Using the `tips` dataset, return a subset of the DataFrame with the highest tip for each `day`.

```{python}
# Your code here:
```

```{python}
# | echo: false
# | eval: false
tips.groupby('day').apply(lambda x: x.sort_values('tip', ascending=False).head(1))
```

:::

::: {.callout-practice title="Practice Q2: Lowest Total Bills per Size"}

In the `tips` dataset, return a subset of the DataFrame with the lowest `total_bill` for each `size` (table size).

```{python}
# Your code here:
tips.groupby('size').apply(lambda x: x.sort_values('total_bill').head(3))
```

:::

## Wrap-Up

In this lesson, you've learned several powerful **group-level data transformations** in pandas:

- **Adding Summary Statistics**: Using `transform()` to add group-level calculations as new columns
- **Counting Within Groups**: Using `value_counts()` to count occurrences in groups 
- **Computing Cumulative Sums**: Tracking running totals within groups
- **Sorting Within Groups**: Finding minimums, maximums, and top N values per group

These techniques allow you to analyze patterns and statistics within specific subsets of your data. Keep practicing with different datasets to build your data manipulation skills!

See you next time!