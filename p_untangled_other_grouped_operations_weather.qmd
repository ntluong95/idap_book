---
title: 'Group-Level Data Transformations in Pandas'
---

```{python}
# | echo: false
# Setup
import pandas as pd

pd.options.display.max_rows = 7
```

## Introduction

In our previous lessons, you've learned how to perform basic data manipulation and aggregation using pandas. Now, we'll take a step further by exploring **group-level data transformations**. These operations allow you to compute statistics and perform calculations within specific groups in your dataset.

Group-level transformations are powerful tools for data analysis, enabling you to uncover patterns and insights that might be hidden when looking at the data as a whole. By the end of this lesson, you'll be equipped with techniques to perform sophisticated analyses within subsets of your data.

## Learning Objectives

By the end of this lesson, you will:

- Add group-level summary statistics as new columns using `transform()`.
- Count values within groups using `value_counts()`.
- Calculate rankings within groups.
- Compute cumulative sums within groups.
- Sort data within groups to extract minimum, maximum, and top N values.

## Imports

This lesson will require `pandas`, `numpy`, `plotly.express`, and `vega_datasets`:

```{python}
import pandas as pd
import numpy as np
import vega_datasets as vd
import plotly.express as px
import calendar
import warnings

warnings.filterwarnings("ignore")

pd.options.mode.copy_on_write = True
```

## Data

We'll use the `seattle_2012` dataset for our examples.

```{python}
seattle_weather = vd.data.seattle_weather()

# Select just 2012 data using query and add a month column
seattle_2012 = seattle_weather.query("date.dt.year == 2012")
seattle_2012["month"] = seattle_2012["date"].dt.strftime("%B")
seattle_2012["month"] = pd.Categorical(
    seattle_2012["month"], categories=list(calendar.month_name)[1:], ordered=True
)
seattle_2012
```

```{python}
la = vd.data.la_riots()
la = la[["age", "gender", "race", "neighborhood", "type"]]
la
```

## Adding Group-Level Summary Statistics Using `transform()`

In the previous lesson, you learned how to calculate summary statistics like mean, median, or standard deviation using `agg()`. 

For example, to compute the mean precipitation (rain + snow) for each month, you could use:

```{python}
seattle_2012.groupby('month').agg(mean_precip = ('precipitation', 'mean'))
```

Sometimes, we want to add these group-level statistics as new columns to our original DataFrame. We can't do this directly with the `agg()` output: 

```{python}
# Does not work
seattle_2012['mean_precip'] = seattle_2012.groupby('month').agg(mean_precip = ('precipitation', 'mean'))
seattle_2012
```

But we can do this using `transform()`. `transform()` reshapes the output to match the original DataFrame's shape, allowing us to add the group-level statistics as new columns.

```{python}
seattle_2012['mean_precip_month'] = seattle_2012.groupby('month')['precipitation'].transform('mean')
seattle_2012
```

Now we can, for example, calculate the difference between the actual precipitation and the average precipitation for that month:

```{python}
seattle_2012['precip_diff_from_mean'] = seattle_2012['precipitation'] - seattle_2012['mean_precip_month']
seattle_2012
```

You can compute other statistics similarly. For example, to compute the median precipitation for each month, you could use:

```{python}
seattle_2012['prep_median_month'] = seattle_2012.groupby('month')['precipitation'].transform('median')    
seattle_2012
```

And we can use custom functions too. For example, to compute the range of `precipitation` within each month, we can define a function and use it with `transform()`:

```{python}
# Define a function to compute range
def prep_range(x):
    return x.max() - x.min()

# Add precipitation range per month as a new column
seattle_2012['prep_range_month'] = seattle_2012.groupby('month')['precipitation'].transform(prep_range)
seattle_2012
```

Or we could use a lambda function for the same result:

```{python}
seattle_2012['prep_range_month'] = seattle_2012.groupby('month')['precipitation'].transform(lambda x: x.max() - x.min())
seattle_2012
```

::: {.callout-tip title="Practice"}

## Practice Q: Mean tip amount by sex

Using the `tips` dataset, add a new column `mean_tip_sex` that contains the mean tip amount for each sex (`Male` or `Female`).

```{python}
# Your code here:
tips = px.data.tips()
tips
```

```{python}
# Your code here:
tips['mean_tip_sex'] = tips.groupby('sex')['tip'].transform('mean')
tips[['sex', 'tip', 'mean_tip_sex']].head()
```

:::

Let's reinitialize the `seattle_2012` DataFrame to a smaller set of columns:

```{python}
seattle_2012 = seattle_2012[['date', 'month', 'precipitation', 'wind', 'weather']]
seattle_2012
```


## Counting Values Within Groups Using `value_counts()`

Counting occurrences of categorical variables within groups can reveal interesting patterns, and you often need to do this after using `groupby()`.

First, let's recall how `value_counts()` works on the entire DataFrame.

```{python}
# Count of weather types
seattle_2012['weather'].value_counts(sort=False)
```

We can add `normalize=True` to get proportions:

```{python}
seattle_2012['weather'].value_counts(normalize=True)
```

Now, to count weather types within each month, we first group by `month`, then subset the `weather` column and apply `value_counts()` to it.

```{python}
# Counts of weather types per month
seattle_2012.groupby('month')['weather'].value_counts()
```

This returns a Series with a MultiIndex, which can be converted to a regular DataFrame with `reset_index()`:

```{python}
seattle_2012.groupby('month')['weather'].value_counts().reset_index()
```

The `value_counts()` method automatically sorts in descending order of counts. To preserve the order of the categories, we can use `sort=False`:

```{python}
seattle_2012.groupby('month')['weather'].value_counts(sort=False)
```

```{python}
seattle_2012.groupby(['month', 'weather']).size()
```

::: {.callout-tip title="Practice"}

## Practice Q: Count Smokers and Non-Smokers by Day

Using the `tips` dataset, count the number of smokers and non-smokers for each day.

```{python}
# Your code here:
smoker_counts = tips.groupby('day')['smoker'].value_counts().reset_index(name='count')
smoker_counts
```

:::

## Counting Values that Meet a Condition

To count the number of values that meet a condition within groups, the most conceptually straightforward approach is to create a new boolean column and then apply `value_counts()` to it. For example, to count the number of days with more than 10 inches of precipitation:

```{python}
seattle_2012['high_precip'] = seattle_2012['precipitation'] > 10
seattle_2012['high_precip'].value_counts()
```

We can now group by `month` and count the number of `True` values per month:

```{python}
out = seattle_2012.groupby('month')['high_precip'].value_counts().reset_index()
out
```

::: {.callout-tip title="Practice"}

## Practice Q: Count Time of Day per Sex

In the `tips` dataset, count how many times each sex (`Male`, `Female`) appears in each time category (`Lunch`, `Dinner`).

```{python}
# Your code here:
sex_time_counts = tips.groupby('sex')['time'].value_counts().reset_index(name='count')
sex_time_counts
```

:::

## Calculating Rankings Within Groups

Ranking data within groups helps identify relative positions, like top performers in each category.

### Overall Ranking

Without grouping, we can rank the entire DataFrame.

```{python}
# Rank dates by precipitation
seattle_2012['prep_rank'] = seattle_2012['precipitation'].rank(method='dense', ascending=False)
seattle_2012[['date', 'precipitation', 'prep_rank']].sort_values('prep_rank').head()
```

### Group-Level Ranking

To rank precipitation within each month:

```{python}
# Rank precipitation within each month
seattle_2012['prep_rank_month'] = seattle_2012.groupby('month')['precipitation'].rank(method='dense', ascending=False)
seattle_2012[['date', 'month', 'precipitation', 'prep_rank_month']].sort_values(['month', 'prep_rank_month']).head(15)
```

### Example: Ranking Precipitation Within Months

Suppose we want to see how each day's precipitation ranks within its month.

```{python}
# Rank precipitation within each month
seattle_2012['prep_rank_month'] = seattle_2012.groupby('month')['precipitation'].rank(method='dense', ascending=False)
seattle_2012[['date', 'month', 'precipitation', 'prep_rank_month']].sort_values(['month', 'prep_rank_month']).head(15)
```

### Practice Questions

::: {.callout-practice title="Practice Q1: Rank Tips by Day"}

Using the `tips` dataset, rank the tips within each day (`Sun`, `Sat`, etc.), adding a new column `tip_rank_day`.

```{python}
# Your code here:
tips['tip_rank_day'] = tips.groupby('day')['tip'].rank(method='dense', ascending=False)
tips[['day', 'tip', 'tip_rank_day']].sort_values(['day', 'tip_rank_day']).head()
```

:::

::: {.callout-practice title="Practice Q2: Rank Total Bill by Size"}

In the `tips` dataset, rank the `total_bill` within each `size` (number of people at the table), adding a new column `bill_rank_size`.

```{python}
# Your code here:
tips['bill_rank_size'] = tips.groupby('size')['total_bill'].rank(method='dense', ascending=False)
tips[['size', 'total_bill', 'bill_rank_size']].sort_values(['size', 'bill_rank_size']).head()
```

:::

## Computing Cumulative Sums Within Groups

Cumulative sums help track running totals within groups.

### Overall Cumulative Sum

Without grouping:

```{python}
# Cumulative sum of precipitation
seattle_2012['prep_cumsum'] = seattle_2012['precipitation'].cumsum()
seattle_2012[['date', 'precipitation', 'prep_cumsum']].head()
```

### Group-Level Cumulative Sum

To compute cumulative precipitation within each month:

```{python}
# Cumulative precipitation per month
seattle_2012['prep_cumsum_month'] = seattle_2012.groupby('month')['precipitation'].cumsum()
seattle_2012[['date', 'month', 'precipitation', 'prep_cumsum_month']].head()
```

### Example: Cumulative Precipitation Difference from Monthly Mean

Suppose we want the cumulative difference between `precipitation` and the monthly mean `precipitation`.

```{python}
# First, calculate the difference
seattle_2012['prep_diff'] = seattle_2012['precipitation'] - seattle_2012['prep_mean_month']

# Then, compute cumulative sum within each month
seattle_2012['prep_diff_cumsum_month'] = seattle_2012.groupby('month')['prep_diff'].cumsum()
seattle_2012[['date', 'month', 'prep_diff', 'prep_diff_cumsum_month']].head()
```

### Practice Questions

::: {.callout-practice title="Practice Q1: Cumulative Tip Amount by Day"}

Using the `tips` dataset, compute the cumulative sum of `tip` for each `day`, adding a new column `cumulative_tip_day`.

```{python}
# Your code here:
tips['cumulative_tip_day'] = tips.groupby('day')['tip'].cumsum()
tips[['day', 'tip', 'cumulative_tip_day']].head()
```

:::

::: {.callout-practice title="Practice Q2: Cumulative Total Bill by Time"}

In the `tips` dataset, compute the cumulative sum of `total_bill` for each `time` (`Lunch`, `Dinner`), adding a new column `cumulative_bill_time`.

```{python}
# Your code here:
tips['cumulative_bill_time'] = tips.groupby('time')['total_bill'].cumsum()
tips[['time', 'total_bill', 'cumulative_bill_time']].head()
```

:::

## Sorting Data Within Groups to Extract Extremes

Sorting within groups allows us to find minimums, maximums, or top N values in each group.

### Overall Sorting

Without grouping:

```{python}
# Sort by precipitation descending
seattle_2012_sorted = seattle_2012.sort_values('precipitation', ascending=False)
seattle_2012_sorted[['date', 'precipitation']].head()
```

### Sorting Within Groups

To sort precipitation within each month:

```{python}
# Sort precipitation within each month
seattle_sorted_month = seattle_2012.groupby('month', group_keys=False).apply(lambda x: x.sort_values('precipitation', ascending=False))
seattle_sorted_month[['date', 'month', 'precipitation']].head(15)
```

### Extracting Top N Values Within Groups

Suppose we want the top 3 days with the highest precipitation in each month.

```{python}
# Add rank within month
seattle_2012['prep_rank_month'] = seattle_2012.groupby('month')['precipitation'].rank(method='first', ascending=False)

# Filter top 3
top_3_precip_days = seattle_2012[seattle_2012['prep_rank_month'] <= 3]
top_3_precip_days[['date', 'month', 'precipitation', 'prep_rank_month']].sort_values(['month', 'prep_rank_month'])
```

### Finding Minimum Values Within Groups

Similarly, to find the days with the lowest precipitation:

```{python}
# Add rank within month
seattle_2012['prep_rank_month_asc'] = seattle_2012.groupby('month')['precipitation'].rank(method='first', ascending=True)

# Filter top 3 days with least precipitation
top_3_low_prep_days = seattle_2012[seattle_2012['prep_rank_month_asc'] <= 3]
top_3_low_prep_days[['date', 'month', 'precipitation', 'prep_rank_month_asc']].sort_values(['month', 'prep_rank_month_asc'])
```

### Practice Questions

::: {.callout-practice title="Practice Q1: Top 2 Highest Tips per Day"}

Using the `tips` dataset, find the top 2 highest tips for each `day`.

```{python}
# Your code here:
tips['tip_rank_day'] = tips.groupby('day')['tip'].rank(method='first', ascending=False)
top_2_tips_per_day = tips[tips['tip_rank_day'] <= 2]
top_2_tips_per_day[['day', 'tip', 'tip_rank_day']].sort_values(['day', 'tip_rank_day'])
```

:::

::: {.callout-practice title="Practice Q2: Lowest Total Bills per Size"}

In the `tips` dataset, find the lowest 3 `total_bill` amounts for each `size` (table size).

```{python}
# Your code here:
tips['bill_rank_size'] = tips.groupby('size')['total_bill'].rank(method='first', ascending=True)
lowest_3_bills_per_size = tips[tips['bill_rank_size'] <= 3]
lowest_3_bills_per_size[['size', 'total_bill', 'bill_rank_size']].sort_values(['size', 'bill_rank_size'])
```

:::

## Wrap-Up

In this lesson, you've learned how to perform various **group-level data transformations** in pandas:

- **Adding Group-Level Summary Statistics**: Using `transform()` to add mean, median, standard deviation, or custom calculations as new columns.
- **Counting Values Within Groups**: Combining `groupby()` with `value_counts()` to count occurrences of categorical variables within groups.
- **Calculating Rankings Within Groups**: Ranking data within groups to find relative positions.
- **Computing Cumulative Sums Within Groups**: Tracking running totals or cumulative differences within groups.
- **Sorting Data Within Groups to Extract Extremes**: Sorting within groups to find minimums, maximums, or top N values.

These techniques are invaluable for data analysis, allowing you to gain deeper insights by examining patterns and statistics within specific subsets of your data.

Continue practicing these operations with different datasets to solidify your understanding and enhance your data manipulation skills.

See you next time!